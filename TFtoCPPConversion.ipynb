{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9cb40a5f",
   "metadata": {},
   "source": [
    "# Conversion from Tensorflow to Onnx to C++\n",
    "\n",
    "This notebook lays out the process of converting trained neural networks to C++ representations using SOFIE. I ran into a few difficulties, though, which I'll discuss below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c202a19f",
   "metadata": {},
   "source": [
    "## Tensorflow to Onnx\n",
    "\n",
    "In the KKTrain folder, the trained models have already been saved in h5 format. The code below converts the saved .h5 file into a .pb file (Tensorflow's Saved Model format). This approach worked on both NERSC and my local machine. However, this does not work on flavor02. I'm not sure if it's the tensorflow installation or another issue. (The error that I receive is a TypeError.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba40de30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "keras.engine.functional.Functional"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "!mkdir -p \"saved_model\"\n",
    "\n",
    "model = tf.keras.models.load_model('TrainBkg.h5', compile=False)\n",
    "tf.saved_model.save(model, 'saved_model/my_saved_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f57556d6",
   "metadata": {},
   "source": [
    "It's also possible to insert this without saving as an .h5 file first. Use the following code after training the model, where `model` is the neural network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c7c4ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p \"saved_model\"\n",
    "\n",
    "tf.saved_model.save(model, 'saved_model/my_saved_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac17d559",
   "metadata": {},
   "source": [
    "Install `pip install -U tf2onnx`. In the command line, while in the directory `KKTrain`, use the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d0333d",
   "metadata": {},
   "outputs": [],
   "source": [
    "python -m tf2onnx.convert --saved-model 'saved_model/my_saved_model' --output model.onnx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec525295",
   "metadata": {},
   "source": [
    "## Onnx to C++\n",
    "Assumes that ROOT has been built from the source using the following commands:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a5286c",
   "metadata": {},
   "outputs": [],
   "source": [
    "git clone git@github.com:root-project/root.git\n",
    "\n",
    "cd root\n",
    "\n",
    "mkdir root_install root_build\n",
    "\n",
    "cd root_build\n",
    "\n",
    "cmake -DCMAKE_INSTALL_PREFIX=../root_install ../ -Dtmva-sofie=ON -Dtmva-pymva=On -DPython3_EXECUTABLE=/global/homes/j/jnzhao3/.conda/envs/train/bin/python3 -DProtobuf_INCLUDE_DIR=~/.local/\n",
    "cmake --build . --target install -j2\n",
    "\n",
    "source <installdir>/bin/thisroot.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c984a512-048f-4113-950f-90060e39de39",
   "metadata": {},
   "source": [
    "Here, I've used the path to my own Python executable. If on another machine, use the following commands to find the path:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63fdce2e-1762-47e9-8d2e-16ebcdf5779e",
   "metadata": {},
   "outputs": [],
   "source": [
    "python3\n",
    "\n",
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce7cbd4-f60a-494f-8be5-64ebdc9c98d5",
   "metadata": {},
   "source": [
    "The current issue: `cmake -DCMAKE_INSTALL_PREFIX=../root_install ../ -Dtmva-sofie=ON -Dtmva-pymva=On -DPython3_EXECUTABLE=/global/homes/j/jnzhao3/.conda/envs/train/bin/python3 -DProtobuf_INCLUDE_DIR=~/.local/` does not compile. I think the issue has to do with NERSC's Cray compiler: https://docs.nersc.gov/development/compilers/wrappers/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "896e1b8b",
   "metadata": {},
   "source": [
    "In the ROOT command line, run the following commands:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b15883",
   "metadata": {},
   "outputs": [],
   "source": [
    "using namespace TMVA::Experimental;\n",
    "SOFIE::RModelParser_ONNX parser;\n",
    "SOFIE::RModel model = parser.Parse(“./model.onnx”);\n",
    "model.Generate();\n",
    "model.OutputGenerated(“./output.hxx”);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3668db4",
   "metadata": {},
   "source": [
    "Unfortunately, I ran into errors while installing ROOT from the source on my local device. Because of the issues with converting to Saved Model format on flavor02, I was not able to proceed until this point. Hence, I don't have completed models to show. However, this works just fine on NERSC (where I unfortunately forgot to save my work)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "train",
   "language": "python",
   "name": "train"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
